{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-04T01:20:51.448422Z","iopub.execute_input":"2023-11-04T01:20:51.448992Z","iopub.status.idle":"2023-11-04T01:20:52.039613Z","shell.execute_reply.started":"2023-11-04T01:20:51.448935Z","shell.execute_reply":"2023-11-04T01:20:52.038419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 하드웨어 가속기 확인하기","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:28:42.996826Z","iopub.execute_input":"2023-10-29T14:28:42.997732Z","iopub.status.idle":"2023-10-29T14:28:43.001725Z","shell.execute_reply.started":"2023-10-29T14:28:42.997696Z","shell.execute_reply":"2023-10-29T14:28:43.000766Z"}}},{"cell_type":"code","source":"import math, re, os\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:20:53.201411Z","iopub.execute_input":"2023-11-04T01:20:53.201812Z","iopub.status.idle":"2023-11-04T01:20:58.809808Z","shell.execute_reply.started":"2023-11-04T01:20:53.201784Z","shell.execute_reply":"2023-11-04T01:20:58.808687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n\n# # GPU 확인\n# gpus = tf.config.list_physical_devices('GPU')\n# if gpus:\n#     for gpu in gpus:\n#         print(f\"GPU 사용 가능: {gpu}\")\n# else:\n#     print(\"GPU 사용 불가능\")\n\n# # TPU 확인\n# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU 확인\n#     print('TPU 사용 가능:', tpu.master())\n# except ValueError:\n#     print(\"TPU 사용 불가능\")\n\n# # CPU 확인\n# cpus = tf.config.list_physical_devices('CPU')\n# if cpus:\n#     print(f\"CPU 사용 가능: {cpus[0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:18:34.628257Z","iopub.execute_input":"2023-11-04T01:18:34.628569Z","iopub.status.idle":"2023-11-04T01:19:09.398614Z","shell.execute_reply.started":"2023-11-04T01:18:34.628545Z","shell.execute_reply":"2023-11-04T01:19:09.397728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 확인하기","metadata":{}},{"cell_type":"code","source":"# Train Data\ntfrecord_file_path_train = '/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/00-192x192-798.tfrec'\n\n# TFRecord 파일에서 첫 번째 레코드를 읽어서 파싱\nraw_dataset = tf.data.TFRecordDataset(tfrecord_file_path_train)\n\n# 첫 번째 레코드만 읽어들임\nfor raw_record in raw_dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(raw_record.numpy())\n    print(example)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:21:08.041616Z","iopub.execute_input":"2023-11-04T01:21:08.042286Z","iopub.status.idle":"2023-11-04T01:21:08.129217Z","shell.execute_reply.started":"2023-11-04T01:21:08.042231Z","shell.execute_reply":"2023-11-04T01:21:08.127993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _parse_function(example_proto):\n    features = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'class': tf.io.FixedLenFeature([], tf.int64),\n        'id': tf.io.FixedLenFeature([], tf.string),\n    }\n    return tf.io.parse_single_example(example_proto, features)\n\ntrain_files = tf.io.gfile.glob('/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/*.tfrec')\nraw_train_dataset = tf.data.TFRecordDataset(train_files)\nprint(raw_train_dataset)\nparsed_train_dataset = raw_train_dataset.map(_parse_function)\nprint(parsed_train_dataset)\n\nunique_labels = set()\nfor parsed_record in parsed_train_dataset:\n    unique_labels.add(parsed_record['class'].numpy())\n\nnum_labels = len(unique_labels)\nprint(f'Total unique labels in the train dataset: {num_labels}')","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:48:20.601944Z","iopub.execute_input":"2023-11-04T01:48:20.602402Z","iopub.status.idle":"2023-11-04T01:48:22.660897Z","shell.execute_reply.started":"2023-11-04T01:48:20.602369Z","shell.execute_reply":"2023-11-04T01:48:22.659530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 전처리","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:42:11.361450Z","iopub.execute_input":"2023-10-29T15:42:11.362404Z","iopub.status.idle":"2023-10-29T15:42:11.366503Z","shell.execute_reply.started":"2023-10-29T15:42:11.362370Z","shell.execute_reply":"2023-10-29T15:42:11.365382Z"}}},{"cell_type":"code","source":"def parse_tfrecord_function(example_proto, include_label=True):\n    if include_label:\n        image_feature_description = {\n            'image': tf.io.FixedLenFeature([], tf.string),\n            'class': tf.io.FixedLenFeature([], tf.int64),\n            'id': tf.io.FixedLenFeature([], tf.string),\n        }\n    else:\n        image_feature_description = {\n            'image': tf.io.FixedLenFeature([], tf.string),\n            'id': tf.io.FixedLenFeature([], tf.string),\n        }\n    return tf.io.parse_single_example(example_proto, image_feature_description)\n\ndef load_dataset(filenames, include_label=True):\n    raw_dataset = tf.data.TFRecordDataset(filenames)\n    parsed_dataset = raw_dataset.map(lambda x: parse_tfrecord_function(x, include_label))\n    return parsed_dataset\n\nfile_paths = [\n    \"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/\",\n    \"/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/\",\n    \"/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/\",\n    \"/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/\",\n]\n\ntrain_dataset = None\nval_dataset = None\ntest_dataset = None\n\n# 각 파일 경로를 순회하며 데이터셋을 로드\nfor base_path in file_paths:\n    train_files = tf.io.gfile.glob(base_path + 'train/*.tfrec')\n    test_files = tf.io.gfile.glob(base_path + 'test/*.tfrec')\n    val_files = tf.io.gfile.glob(base_path + 'val/*.tfrec')\n    \n    if train_files:\n        new_train_dataset = load_dataset(train_files, include_label=True)\n        train_dataset = new_train_dataset if train_dataset is None else train_dataset.concatenate(new_train_dataset)\n    \n    if test_files:\n        new_test_dataset = load_dataset(test_files, include_label=False) # 레이블을 포함하지 않음\n        test_dataset = new_test_dataset if test_dataset is None else test_dataset.concatenate(new_test_dataset)\n        \n    if val_files:\n        new_val_dataset = load_dataset(val_files, include_label=True)\n        val_dataset = new_val_dataset if val_dataset is None else val_dataset.concatenate(new_val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:48:22.662919Z","iopub.execute_input":"2023-11-04T01:48:22.663330Z","iopub.status.idle":"2023-11-04T01:48:22.989722Z","shell.execute_reply.started":"2023-11-04T01:48:22.663302Z","shell.execute_reply":"2023-11-04T01:48:22.988452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train Dataset: {train_dataset}')\nprint(f'Test Dataset: {test_dataset}')\nprint(f'Validation Dataset: {val_dataset}')","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:48:22.990773Z","iopub.execute_input":"2023-11-04T01:48:22.991031Z","iopub.status.idle":"2023-11-04T01:48:22.996289Z","shell.execute_reply.started":"2023-11-04T01:48:22.991008Z","shell.execute_reply":"2023-11-04T01:48:22.995404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(features):\n    image = tf.image.decode_jpeg(features['image'], channels=3)\n\n    # 레이블 데이터\n    label = features['class']\n\n    # 이미지 데이터\n    image = tf.image.resize(image, [512, 512])\n    image = tf.cast(image, tf.float32) / 255.0\n\n    # 레이블을 원-핫 인코딩\n    label = tf.one_hot(label, depth=104)\n    return image, label\n\n# 전처리 적용 전 데이터셋에서 하나의 배치 샘플링 및 출력\nfor features in train_dataset.take(1):\n    print(\"전처리 전:\")\n    print(\"이미지 데이터:\", features['image'])\n    print(\"레이블 데이터:\", features['class'])\n\n# 전처리 적용\ntrain_dataset = train_dataset.map(preprocess)\nval_dataset = val_dataset.map(preprocess)\n\n# 전처리 적용 후 데이터셋에서 하나의 배치 샘플링 및 출력\nfor images, labels in train_dataset.take(1):\n    print(\"전처리 후:\")\n    print(\"이미지 데이터:\", images.numpy()[0]) \n    print(\"레이블 데이터:\", labels.numpy()[0]) \n    \n# 배치 사이즈 적용\ntrain_dataset = train_dataset.batch(32)\nval_dataset = val_dataset.batch(32)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:48:22.997767Z","iopub.execute_input":"2023-11-04T01:48:22.998006Z","iopub.status.idle":"2023-11-04T01:48:23.180338Z","shell.execute_reply.started":"2023-11-04T01:48:22.997986Z","shell.execute_reply":"2023-11-04T01:48:23.178968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 모델링","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:42:16.968749Z","iopub.execute_input":"2023-10-29T15:42:16.969106Z","iopub.status.idle":"2023-10-29T15:42:16.977083Z","shell.execute_reply.started":"2023-10-29T15:42:16.969077Z","shell.execute_reply":"2023-10-29T15:42:16.976096Z"}}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications import VGG16\n\ntf.keras.backend.clear_session()\n\nwith strategy.scope():\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='swish', input_shape=(512, 512, 3)),\n        MaxPooling2D(2, 2),\n        Conv2D(64, (3, 3), activation='swish'),\n        MaxPooling2D(2, 2),\n        Conv2D(128, (3, 3), activation='swish'),\n        MaxPooling2D(2, 2),\n        Conv2D(128, (3, 3), activation='swish'),\n        MaxPooling2D(2, 2),\n\n        Flatten(),\n        Dense(512, activation='swish'),\n        Dropout(0.5),\n        Dense(104, activation='softmax')\n    ])\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:33:40.837148Z","iopub.execute_input":"2023-11-04T01:33:40.837495Z","iopub.status.idle":"2023-11-04T01:33:43.376629Z","shell.execute_reply.started":"2023-11-04T01:33:40.837471Z","shell.execute_reply":"2023-11-04T01:33:43.375487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\nhistory = model.fit(train_dataset,\n                    validation_data=val_dataset,\n                    epochs=100,\n                    callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:33:44.289730Z","iopub.execute_input":"2023-11-04T01:33:44.290094Z","iopub.status.idle":"2023-11-04T01:44:23.844664Z","shell.execute_reply.started":"2023-11-04T01:33:44.290066Z","shell.execute_reply":"2023-11-04T01:44:23.843577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# 정확도 그래프\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.legend(loc='lower right')\n\n# 손실 그래프\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend(loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:44:23.847425Z","iopub.execute_input":"2023-11-04T01:44:23.847927Z","iopub.status.idle":"2023-11-04T01:44:24.217024Z","shell.execute_reply.started":"2023-11-04T01:44:23.847897Z","shell.execute_reply":"2023-11-04T01:44:24.215900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### csv 파일로 만들기","metadata":{}},{"cell_type":"code","source":"# test_dataset에 대한 전처리 함수 정의\ndef preprocess_test(features):\n    image = tf.image.decode_jpeg(features['image'], channels=3)\n    image = tf.image.resize(image, [512, 512])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image, features['id']\n\n# test_dataset에 전처리 함수 적용\ntest_dataset = test_dataset.map(preprocess_test).batch(128)\n\n# 모델을 사용해 예측하기\npredicted_classes = []\nimage_ids = []\n\nfor images, ids in test_dataset:\n    predictions = model.predict(images)\n    predicted_classes.extend(tf.argmax(predictions, axis=-1).numpy()) # 예측된 클래스 저장\n    image_ids.extend([id_str.decode('utf-8') for id_str in ids.numpy()]) # id 값을 bytes에서 string으로 변환하여 저장\n\n\n# 예측 결과와 이미지 ID 매핑\nresults = pd.DataFrame({\n    'id': image_ids,\n    'label': predicted_classes  # 'class' 대신 'label'을 사용\n})\n\nresults = results.drop_duplicates(subset='id', keep='first')  # 첫 번째로 나타나는 'id'만 유지하고 나머지는 제거\n\n# 결과를 CSV 파일로 저장\nresults.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T01:48:27.573391Z","iopub.execute_input":"2023-11-04T01:48:27.574137Z","iopub.status.idle":"2023-11-04T01:53:25.540894Z","shell.execute_reply.started":"2023-11-04T01:48:27.574101Z","shell.execute_reply":"2023-11-04T01:53:25.539899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}